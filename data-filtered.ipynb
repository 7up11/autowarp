{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d5242-55ac-45ad-b511-97a12eaa0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "from glob import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51df60b-3712-4a20-a6e3-017ce09d5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(labels):\n",
    "    with open(labels) as f:\n",
    "        labels = f.read()\n",
    "    labels = labels.strip().split(\"\\n\")\n",
    "    labels = [line.strip().split() for line in labels]\n",
    "    segments = []\n",
    "    for line in labels:\n",
    "        class_ = int(line[0])\n",
    "        contour = np.array([[float(line[i]), float(line[i + 1])] for i in range(1, len(line), 2)])\n",
    "        segments.append([class_, contour])\n",
    "    return segments\n",
    "\n",
    "def normal_to_image(image_shape, contour):\n",
    "    h, w, _ = image_shape\n",
    "    return (contour * (w, h)).astype(int)\n",
    "\n",
    "def draw_labels(image, labels):\n",
    "    if type(image) == str:\n",
    "        image = cv.imread(image)\n",
    "    if type(labels) == str:\n",
    "        labels = load_labels(labels)\n",
    "        for segment in labels:\n",
    "            segment[1] = normal_to_image(image.shape, segment[1])\n",
    "    for class_, contour in labels:\n",
    "        image = cv.polylines(image, [contour], True, (255, 0, 0))\n",
    "        image = cv.putText(image, str(class_), contour[0], cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a034dfc-a0dd-4cee-a476-ae787868c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: ChatGPT\n",
    "def perpendicular_distance(point, start, end):\n",
    "    \"\"\"Calculate the perpendicular distance from a point to a line segment.\"\"\"\n",
    "    if np.all(start == end):\n",
    "        return euclidean(point, start)\n",
    "    \n",
    "    line_vec = end - start\n",
    "    point_vec = point - start\n",
    "    line_len = np.dot(line_vec, line_vec)\n",
    "    t = max(0, min(1, np.dot(point_vec, line_vec) / line_len))\n",
    "    projection = start + t * line_vec\n",
    "    return euclidean(point, projection)\n",
    "\n",
    "# Credit: ChatGPT\n",
    "def rdp(contour, epsilon):\n",
    "    \"\"\"\n",
    "    Applies the Ramer-Douglas-Peucker (RDP) algorithm to simplify a contour.\n",
    "    \n",
    "    Parameters:\n",
    "        contour (np.ndarray): A Nx2 array of (x, y) coordinates.\n",
    "        epsilon (float): Tolerance for point reduction (higher -> more aggressive).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Simplified contour as a Nx2 array.\n",
    "    \"\"\"\n",
    "    if len(contour) < 3:\n",
    "        return contour\n",
    "\n",
    "    # Find the point with the maximum perpendicular distance\n",
    "    start, end = contour[0], contour[-1]\n",
    "    distances = np.array([perpendicular_distance(p, start, end) for p in contour[1:-1]])\n",
    "    \n",
    "    max_idx = np.argmax(distances)\n",
    "    max_dist = distances[max_idx]\n",
    "    \n",
    "    if max_dist > epsilon:\n",
    "        max_idx += 1  # Offset for skipping the first point\n",
    "        # Recursive RDP on both segments\n",
    "        left = rdp(contour[:max_idx+1], epsilon)\n",
    "        right = rdp(contour[max_idx:], epsilon)\n",
    "        return np.vstack((left[:-1], right))\n",
    "    else:\n",
    "        return np.array([start, end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfcb3b8-d7bb-44bd-a087-a810fc17dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_names(path):\n",
    "    files = glob(str(path / \"images\" / \"*.jpg\"))\n",
    "    return [Path(f).stem for f in files]\n",
    "\n",
    "def image_path(path, image, check=False):\n",
    "    path = path / \"images\" / f\"{image}.jpg\"\n",
    "    if check and not path.exists():\n",
    "        return None\n",
    "    else:\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        return path\n",
    "\n",
    "def labels_path(path, image, check=False):\n",
    "    path = path / \"labels\" / f\"{image}.txt\"\n",
    "    if check and not path.exists():\n",
    "        return None\n",
    "    else:\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        return path\n",
    "\n",
    "def filter_image(epsilon, min_, max_, src, dst, image):\n",
    "    if (labels := labels_path(src, image, check=True)) is None:\n",
    "        return\n",
    "    labels = load_labels(labels)\n",
    "    segments = []\n",
    "    for class_, contour in labels:\n",
    "        simple = rdp(contour, epsilon)\n",
    "        if min_ <= simple.shape[0] and simple.shape[0] <= max_:\n",
    "            segments.append([class_] + contour.flatten().tolist())\n",
    "    if len(segments) > 0:\n",
    "        shutil.copy(image_path(src, image), image_path(dst, image))\n",
    "        with open(labels_path(dst, image), \"w\") as f:\n",
    "            for segment in segments:\n",
    "                segment = [str(x) for x in segment]\n",
    "                f.write(\" \".join(segment) + \"\\n\")\n",
    "\n",
    "def equal_slices(n, xs):\n",
    "    if len(xs) < n:\n",
    "        raise ValueError()\n",
    "    slice_len = len(xs) // n\n",
    "    remainder = len(xs) % n\n",
    "    slices = [slice(slice_len * i, slice_len * (i + 1)) for i in range(n)]\n",
    "    if remainder > 0:\n",
    "        slices[-1] = slice(slice_len * (n - 1), slice_len * n + remainder)\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99008e4f-e0aa-4c67-af23-8247fdbe4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"datasets/coco2017/train\")\n",
    "filtered_path = Path(\"datasets/coco2017-filtered/train\")\n",
    "contour_epsilon = 0.05\n",
    "contour_min = 4\n",
    "contour_max = 7\n",
    "chunks = 40\n",
    "\n",
    "def filter_chunk(images):\n",
    "    for image in images:\n",
    "        filter_image(contour_epsilon, contour_min, contour_max, dataset_path, filtered_path, image)\n",
    "\n",
    "if filtered_path.exists():\n",
    "    shutil.rmtree(filtered_path)\n",
    "with ThreadPoolExecutor(max_workers=chunks) as executor:\n",
    "    images = image_names(dataset_path)\n",
    "    slices = equal_slices(chunks, images)\n",
    "    futures = [executor.submit(filter_chunk, images[s]) for s in slices]\n",
    "    for future in futures:\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191a187-8588-4507-805f-ecf188408bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
